{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data (pre-)processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fcsy import DataFrame\n",
    "\n",
    "# Performance & evaluation\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from statistics import mean, median\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from GMMClassifier import GMMClassifier\n",
    "from FlowSOMClassifier import FlowSOMClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89210a",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOLDERS\n",
    "# Path of pre-processed BLAST110 FCS files\n",
    "BLAST110_FCS_path = \"data/BLAST110/FCS/\"\n",
    "# Path of BLAST110 labeling\n",
    "BLAST110_label_path = \"<ENTER PATH>\"\n",
    "# Path of pre-processed LAIP29 FCS files\n",
    "LAIP29_FCS_path = \"data/LAIP29/FCS/\"\n",
    "# Path of LAIP29 labeling\n",
    "LAIP29_label_path = \"<ENTER PATH>\"\n",
    "\n",
    "# OUTPUT FOLDERS\n",
    "BLAST110_output = \"output/BLAST110/\"\n",
    "LAIP29_output = \"output/LAIP29/\"\n",
    "if not os.path.exists(BLAST110_output):\n",
    "    os.makedirs(BLAST110_output)\n",
    "if not os.path.exists(LAIP29_output):\n",
    "    os.makedirs(LAIP29_output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which markers we use for modeling\n",
    "features = [\"SSC-A_scaled\", \"Horizon V500-A\", \"PerCP-A\", \"PC7-A\"]\n",
    "# Jobs to use for modeling\n",
    "n_jobs = -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d90e6d",
   "metadata": {},
   "source": [
    "# Aggregate training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486ec1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We create a version of 2K and 5K sampled cells per file\n",
    "if not os.path.exists(BLAST110_output + \"/BLAST110_5K.pkl\"):\n",
    "    dataframes_2K = []\n",
    "    dataframes_5K = []\n",
    "    for root, dirs, files in os.walk(BLAST110_FCS_path):\n",
    "        for file in files:\n",
    "            sample_id = \"_\".join(file.split(\"_\")[0:3])\n",
    "            patient_id = \"_\".join(file.split(\"_\")[0:2])\n",
    "            ff = DataFrame.from_fcs(root+file)\n",
    "            labels = pd.read_csv(BLAST110_label_path+sample_id+\".csv\", index_col=0)\n",
    "            ff = pd.merge(ff, labels)\n",
    "            ff = ff[features + [\"Blast\", \"event_ID\"]]\n",
    "            ff[\"patient_id\"] = patient_id\n",
    "            ff[\"sample_id\"] = sample_id\n",
    "            ff_2K = ff.sample(n=2000, random_state=42)\n",
    "            ff_5K = ff.sample(n=5000, random_state=42)\n",
    "            dataframes_2K.append(ff_2K)\n",
    "            dataframes_5K.append(ff_5K)\n",
    "    \n",
    "    # Pickle the output\n",
    "    data = pd.concat(dataframes_2K)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data.to_pickle(BLAST110_output + \"/BLAST110_2K.pkl\")\n",
    "    \n",
    "    data = pd.concat(dataframes_5K)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data.to_pickle(BLAST110_output + \"/BLAST110_5K.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66627b2c",
   "metadata": {},
   "source": [
    "# Models and hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8eab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR():\n",
    "    clf = SGDClassifier(loss=\"log_loss\", n_jobs=n_jobs, \n",
    "                        class_weight=\"balanced\", max_iter=10000, \n",
    "                        random_state=42)\n",
    "    params = {\"alpha\": 10.0**-np.arange(1,7)}    \n",
    "    return clf, params\n",
    "\n",
    "def SVM():\n",
    "    clf = SGDClassifier(loss=\"hinge\", n_jobs=n_jobs, \n",
    "                        class_weight=\"balanced\", max_iter=10000, \n",
    "                        random_state=42)\n",
    "    params = {\"alpha\": 10.0**-np.arange(1,7)}\n",
    "    return clf, params\n",
    "\n",
    "def RF():\n",
    "    clf = RandomForestClassifier(n_jobs=n_jobs, class_weight=\"balanced\", \n",
    "                                 random_state=42)\n",
    "    params = {\"max_depth\" : range(2, 11),\n",
    "              \"min_samples_split\": range(100, 10001),\n",
    "              \"min_samples_leaf\": range(100, 10001)}\n",
    "    return clf, params\n",
    "\n",
    "def LightGBM():\n",
    "    clf = lgb.LGBMClassifier(verbose=-1, n_jobs=n_jobs, objective=\"binary\", \n",
    "                             is_unbalance=True, random_state=42)\n",
    "    params = {\"n_estimators\": range(50, 1001),\n",
    "              \"num_leaves\": range(2, 31),\n",
    "              \"max_depth\": range(2, 11),\n",
    "              \"lambda_l2\": range(0, 201)}\n",
    "    return clf, params\n",
    "\n",
    "def GMMclf():\n",
    "    clf = GMMClassifier(random_state=42)\n",
    "    params = {\"n_components_class0\": range(1, 21),\n",
    "              \"n_components_class1\": range(1, 11)}\n",
    "    return clf, params\n",
    "\n",
    "def FlowSOMclf():\n",
    "    clf = FlowSOMClassifier(random_state=42)\n",
    "    params = {\"ratio_threshold\": [0.5, 1, 2.5, 5, 7.5, 10]}\n",
    "    return clf, params\n",
    "    \n",
    "models = {\"LR\": LR(),\n",
    "          \"SVM\": SVM(),\n",
    "          \"RF\": RF(),\n",
    "          \"LightGBM\": LightGBM(),\n",
    "          \"GMMclf\": GMMclf(),\n",
    "          \"FlowSOMclf\": FlowSOMclf()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c950d39",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "data_train = pd.read_pickle(BLAST110_output + \"/BLAST110_2K.pkl\") \n",
    "\n",
    "X = data_train[features]\n",
    "y = data_train[\"Blast\"]\n",
    "groups = data_train[\"patient_id\"]\n",
    "samples = data_train[\"sample_id\"]\n",
    "\n",
    "# Define inner and outer CV\n",
    "outer_CV = GroupKFold(n_splits=10)\n",
    "inner_CV = GroupKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c572144",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60e47d",
   "metadata": {},
   "source": [
    "**NOTE: The following block takes multiple hours to run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3030352",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BLAST110_output + \"/CV/\"):\n",
    "    os.makedirs(BLAST110_output + \"/CV/\")\n",
    "    \n",
    "# Make the outer CV split\n",
    "for i, (train_index, test_index) in enumerate(outer_CV.split(X, y, groups)):\n",
    "    # Get training and test set\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    train_groups = groups[train_index]\n",
    "    test_groups = groups[test_index]\n",
    "    train_ids = groups[train_index].unique()\n",
    "    test_ids = groups[test_index].unique()\n",
    "    # Use sample IDs to load the full FCS files in the inner split\n",
    "    sample_ids = samples[test_index].unique()\n",
    "\n",
    "    # Load the full test data for every outer fold\n",
    "    test_data = []\n",
    "    for sample_id in sample_ids:\n",
    "        ff = DataFrame.from_fcs(BLAST110_FCS_path+sample_id+\"_preprocessed.fcs\")\n",
    "        labels = pd.read_csv(BLAST110_label_path+sample_id+\".csv\", index_col=0)\n",
    "        ff = pd.merge(ff, labels)\n",
    "        ff = ff[features + [\"Blast\", \"event_ID\"]]\n",
    "        ff[\"patient_id\"] = \"_\".join(sample_id.split(\"_\")[:-1])\n",
    "        ff[\"sample_id\"] = sample_id\n",
    "        test_data.append(ff)\n",
    "    test_data = pd.concat(test_data).reset_index(drop=True)\n",
    "\n",
    "    # Perform 10-fold cross-validation in the inner folds\n",
    "    for model in models:\n",
    "        # Check if this modeling iteration was already done\n",
    "        if os.path.isfile(BLAST110_output+\"CV/fold\"+str(i)+\"_\"+model+\"_outerCV.csv\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Fitting\")\n",
    "            print(model)\n",
    "\n",
    "        # Load the model with its associated hyperparameters\n",
    "        clf, params = models[model]\n",
    "\n",
    "        # Optimize hyperparameters\n",
    "        if model in [\"RF\", \"LightGBM\", \"GMMclf\"]:\n",
    "            # For tree-based models, use randomized search\n",
    "            opt = RandomizedSearchCV(clf, params, cv=inner_CV, n_iter=20, \n",
    "                                     n_jobs=n_jobs, random_state=i, refit=\"f1\",\n",
    "                                     scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "            opt.fit(X_train, y_train, groups=train_groups)\n",
    "        else:\n",
    "            # Use gridsearch for logistic regression and SVM\n",
    "            opt = GridSearchCV(clf, params, cv=inner_CV, n_jobs=n_jobs, refit=\"f1\",\n",
    "                               scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "            opt.fit(X=X_train, y=y_train, groups=train_groups)\n",
    "\n",
    "        # Save the training results\n",
    "        cv_results = pd.DataFrame(opt.cv_results_)\n",
    "        cv_results.to_csv(BLAST110_output+\"CV/fold\"+str(i)+\"_\"+model+\"_innerCV.csv\")\n",
    "\n",
    "        # Predict on the individual outer fold samples and save results\n",
    "        model_results = []\n",
    "        for sample_id in sample_ids:\n",
    "            full_test = test_data[test_data[\"sample_id\"]==sample_id]\n",
    "            full_pred = opt.predict(full_test[features])\n",
    "\n",
    "            # Store the results\n",
    "            result_dict = {\"fold\": i,\n",
    "                           \"sample_id\": sample_id,\n",
    "                           \"model\": model,\n",
    "                           \"gt_count\": len(full_test[full_test[\"Blast\"]==1]),\n",
    "                           \"gt_perc\": len(full_test[full_test[\"Blast\"]==1]) / len(full_test),\n",
    "                           \"pred_count\": len(full_pred[full_pred == 1]),\n",
    "                           \"pred_perc\": len(full_pred[full_pred == 1]) / len(full_pred),\n",
    "                           \"accuracy\": accuracy_score(full_test[\"Blast\"], full_pred),\n",
    "                           \"precision\": precision_score(full_test[\"Blast\"], full_pred),\n",
    "                           \"recall\": recall_score(full_test[\"Blast\"], full_pred),\n",
    "                           \"f1\": f1_score(full_test[\"Blast\"], full_pred)}\n",
    "            model_results.append(result_dict)\n",
    "        # Save the model output\n",
    "        pd.DataFrame(model_results).to_csv(BLAST110_output+\"CV/fold\"+str(i)+\"_\"+model+\"_outerCV.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c504187",
   "metadata": {},
   "source": [
    "# Final GMMclf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7605e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a final GMMclf model based on the 5K training dataset\n",
    "if not os.path.exists(BLAST110_output+\"/GMMclf.pkl\"):\n",
    "    # Set up training data\n",
    "    data_train = pd.read_pickle(BLAST110_output + \"/BLAST110_5K.pkl\") \n",
    "    X = data_train[features]\n",
    "    y = data_train[\"Blast\"]\n",
    "    groups = data_train[\"patient_id\"]\n",
    "    CV = GroupKFold(n_splits=10)\n",
    "\n",
    "    # Set up model and hyperparameter search\n",
    "    clf = GMMClassifier(random_state=42)\n",
    "    params = {\"n_components_class0\": range(1, 21),\n",
    "              \"n_components_class1\": range(1, 11)}\n",
    "    opt = GridSearchCV(clf, params, cv=CV, n_jobs=n_jobs, refit=\"f1\",\n",
    "                       scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "    opt.fit(X=X, y=y, groups=groups)\n",
    "    \n",
    "    # Save gridsearch results\n",
    "    pd.DataFrame(opt.cv_results_).to_csv(BLAST110_output+\"/GMMclf_gridsearch.csv\")\n",
    "    \n",
    "    # Save model\n",
    "    clf = opt.best_estimator_\n",
    "    joblib.dump(clf, BLAST110_output+\"/GMMclf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968424ad",
   "metadata": {},
   "source": [
    "# LAIP29 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30ab79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(LAIP29_output + \"/GMMclf_predictions.csv\"):\n",
    "    clf = joblib.load(BLAST110_output+\"/GMMclf.pkl\")\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(LAIP29_FCS_path):\n",
    "        for file in files:\n",
    "            sample_id = \"_\".join(file.split(\"_\")[0:3])\n",
    "            tube = file.split('_')[3]\n",
    "            ff = DataFrame.from_fcs(root+file)\n",
    "            labels = pd.read_csv(LAIP29_label_path+sample_id+\"_\"+tube+\".csv\", index_col=0, low_memory=False)\n",
    "            ff = pd.merge(ff, labels)\n",
    "            ff[\"pred\"] = clf.predict(ff[features])\n",
    "            result_dict = {\"file\":file,\n",
    "                           \"total_count\": len(ff),\n",
    "                           \"total_LAIP_cells\": len(ff[ff[\"LAIP\"]==1]),\n",
    "                           \"total_conserved_LAIP_cells\": len(ff[(ff[\"pred\"]==1)&(ff[\"LAIP\"]==1)]),\n",
    "                           \"gt_count\": len(ff[ff[\"Blast\"]==1]),\n",
    "                           \"pred_count\": len(ff[ff[\"pred\"]==1]),\n",
    "                           \"accuracy\": accuracy_score(ff[\"Blast\"], ff[\"pred\"]),\n",
    "                           \"precision\": precision_score(ff[\"Blast\"], ff[\"pred\"]),\n",
    "                           \"recall\": recall_score(ff[\"Blast\"], ff[\"pred\"]),\n",
    "                           \"f1\": f1_score(ff[\"Blast\"], ff[\"pred\"])}\n",
    "            results.append(result_dict)\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(LAIP29_output + \"/GMMclf_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
