{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b752a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data (pre-)processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fcsy import DataFrame\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Modeling\n",
    "import hdbscan\n",
    "import umap\n",
    "import joblib\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Performance\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOLDERS\n",
    "# Path of preprocessed LAIP29 FCS files\n",
    "LAIP29_FCS_path = \"data/LAIP29/FCS/\"\n",
    "# Path of LAIP29 labeling\n",
    "LAIP29_label_path = \"<ENTER PATH>\"\n",
    "# Path of LAIP29 annotations\n",
    "LAIP29_annotation_path = \"<ENTER PATH>\"\n",
    "\n",
    "# OUTPUT FOLDERS\n",
    "BLAST110_output = \"output/BLAST110\"\n",
    "LAIP29_output = \"output/LAIP29\"\n",
    "RBM18_output = \"output/RBM18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which markers we used for blast prediction\n",
    "features = [\"SSC-A_scaled\", \"Horizon V500-A\", \"PerCP-A\", \"PC7-A\"]\n",
    "# Markers used for reference models\n",
    "markers = [\"FITC-A\", \"PE-A\", \"PerCP-A\", \"PC7-A\", \"APC-A\", \n",
    "           \"APC-H7-A\", \"Horizon V450-A\", \"Horizon V500-A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41533f48",
   "metadata": {},
   "source": [
    "# Reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GMMclf\n",
    "clf = joblib.load(BLAST110_output+\"/GMMclf.pkl\")\n",
    "\n",
    "# Load the WBC regressor\n",
    "reg = joblib.load(BLAST110_output+\"/GMMclf_WBCreg.pkl\")\n",
    "\n",
    "ref_data = {\"GMMclf\":{}, \"manual\":{}}\n",
    "for gating in [\"GMMclf\", \"manual\"]:\n",
    "    for tube in [\"P1\", \"P2\", \"P3\", \"P4\"]:\n",
    "        ref_data[gating][tube] = pd.read_csv(RBM18_output+\"/RBM18_\"+tube+\"_blasts_\"+gating+\".csv\", index_col=0)\n",
    "        \n",
    "# Load the reference models and quantiles\n",
    "refGMMs = {\"GMMclf\":{}, \"manual\":{}}\n",
    "percentiles = {\"GMMclf\":{}, \"manual\":{}}\n",
    "for gating in [\"GMMclf\", \"manual\"]:\n",
    "    for tube in [\"P1\", \"P2\", \"P3\", \"P4\"]:\n",
    "        refGMMs[gating][tube] = joblib.load(RBM18_output+\"/GMMref_\"+tube+\"_\"+gating+\".pkl\")\n",
    "        cutoffs = pd.read_csv(RBM18_output+\"/GMMref_\"+tube+\"_\"+gating+\"_percentiles.csv\", index_col=0)\n",
    "        percentiles[gating][tube] = cutoffs.to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75478b1",
   "metadata": {},
   "source": [
    "# Set up modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485225c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuSVMs = {\"GMMclf\":{}, \"manual\":{}}\n",
    "for gating in [\"GMMclf\", \"manual\"]:\n",
    "    for tube in [\"P1\", \"P2\", \"P3\", \"P4\"]:\n",
    "        transform = Nystroem(gamma=2, random_state=42)\n",
    "        clf_sgd = SGDOneClassSVM(nu=0.05, shuffle=True, fit_intercept=True, random_state=42)\n",
    "        pipe_sgd = make_pipeline(transform, clf_sgd)\n",
    "        nuSVMs[gating][tube] = pipe_sgd.fit(ref_data[gating][tube][markers]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF = {\"GMMclf\":{}, \"manual\":{}}\n",
    "for gating in [\"GMMclf\", \"manual\"]:\n",
    "    for tube in [\"P1\", \"P2\", \"P3\", \"P4\"]:\n",
    "        model = LocalOutlierFactor(novelty=True, contamination=0.05)\n",
    "        LOF[gating][tube] = model.fit(ref_data[gating][tube][markers]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac357fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UMAP_HDBSCAN(test_blasts, ref_blasts):\n",
    "    input_blasts = test_blasts.copy()\n",
    "    if int(len(input_blasts) * 0.8) > len(ref_blasts):\n",
    "        input_blasts = input_blasts.sample(len(ref_blasts), random_state=42)\n",
    "        input_blasts[\"label\"] = \"test\"\n",
    "    else:\n",
    "        ref_blasts = ref_blasts.sample(int(len(input_blasts) * 0.8), random_state=42)\n",
    "        ref_blasts[\"label\"] = \"control\"\n",
    "    \n",
    "    # Aggregate the data\n",
    "    agg = pd.concat([input_blasts, ref_blasts])\n",
    "    agg = shuffle(agg)\n",
    "\n",
    "    # Get 3D UMAP coordinates\n",
    "    reducer = umap.UMAP(min_dist=0, n_components=3, random_state=42, low_memory=False)\n",
    "    reducer = reducer.fit(agg[markers])\n",
    "    embedding = reducer.transform(agg[markers])\n",
    "    embedding = pd.DataFrame(embedding)\n",
    "\n",
    "    # Perform HDBSCAN clustering\n",
    "    hdb = hdbscan.HDBSCAN(min_cluster_size=50, core_dist_n_jobs=1, prediction_data=True)\n",
    "    hdb.fit(embedding.to_numpy())\n",
    "    agg[\"HDBSCAN\"] = hdb.labels_\n",
    "    \n",
    "    # Identify the anomalous cluster\n",
    "    aberrant_dict = {-1: 0}\n",
    "    for i in agg[\"HDBSCAN\"].unique():\n",
    "        if i == -1 or i == '-1':\n",
    "            # Outliers were marked as control in original publication\n",
    "            # Based on email correspondence\n",
    "            aberrant_dict[i] = 0\n",
    "        else:\n",
    "            temp = agg[agg[\"HDBSCAN\"]==i]\n",
    "            frac = len(temp[temp[\"label\"] == \"control\"]) / len(temp)\n",
    "            if frac <= 0.05:\n",
    "                aberrant_dict[i] = 1\n",
    "            else:\n",
    "                aberrant_dict[i] = 0\n",
    "                \n",
    "    # Identify anomalous cells in the original data\n",
    "    embedding = reducer.transform(test_blasts[markers])\n",
    "    embedding = pd.DataFrame(embedding)\n",
    "    test_labels, _ = hdbscan.approximate_predict(hdb, embedding.to_numpy())      \n",
    "    test_blasts[\"HDBSCAN\"] = test_labels\n",
    "    pred = [aberrant_dict[i] for i in test_blasts['HDBSCAN']]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_anomaly(test_blasts, ref_model, cutoff):\n",
    "    test_blasts[\"LLR\"] = ref_model.score_samples(test_blasts[markers])\n",
    "    pred = np.where(test_blasts[\"LLR\"] <= cutoff, 1, 0)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d00d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LAIP29_output + \"/benchmark/\"):\n",
    "    os.makedirs(LAIP29_output + \"/benchmark/\")\n",
    "\n",
    "for root, dirs, files in os.walk(LAIP29_FCS_path):\n",
    "    for file in files:      \n",
    "        print(file)\n",
    "        # Read and process FCS file\n",
    "        sample_id = \"_\".join(file.split(\"_\")[0:4])\n",
    "        patient_id = \"_\".join(file.split(\"_\")[0:2])\n",
    "        timepoint = file.split(\"_\")[2]\n",
    "        tube = file.split('_')[3]\n",
    "        ff = DataFrame.from_fcs(root+file)\n",
    "        labels = pd.read_csv(LAIP29_label_path+sample_id+\".csv\", index_col=0, low_memory=False)\n",
    "        ff = pd.merge(ff, labels)\n",
    "        annotation = pd.read_csv(LAIP29_annotation_path+sample_id+\".csv\", index_col=0, low_memory=False)\n",
    "        biggest_LAIP = list(annotation.sort_values(\"LAIP_WBC\", ascending=False)[\"LAIP_WBC\"])[0]\n",
    "        if biggest_LAIP > 0.1:\n",
    "            MRD_status = 1\n",
    "        else:\n",
    "            MRD_status = 0\n",
    "        LAIP_events = len(ff[ff[\"LAIP\"]==1])\n",
    "\n",
    "        # Predict and save the WBC counts\n",
    "        ff[\"NB_GMM_cluster\"] = clf.gmm_class0.predict(ff[features])\n",
    "        counts = pd.DataFrame(ff[\"NB_GMM_cluster\"].value_counts())\n",
    "        counts = counts.transpose().reset_index(drop=True)\n",
    "        for i in range(0, clf.gmm_class0.n_components):\n",
    "            if i not in counts:\n",
    "                counts[i] = 0\n",
    "        count_cols = [i for i in range(0, clf.gmm_class0.n_components)]\n",
    "        WBC_count_pred = int(reg.predict(counts[count_cols]))\n",
    "        \n",
    "        # Determine manual MRD%\n",
    "        WBC_count_manual = len(ff[ff[\"WBC\"]==1])\n",
    "        LAIP_perc = (LAIP_events / WBC_count_manual) * 100\n",
    "\n",
    "        # Predict blasts\n",
    "        ff[\"GMMclf\"] = clf.predict(ff[features])\n",
    "        for gating in [\"GMMclf\", \"manual\"]:\n",
    "            if gating == \"GMMclf\":\n",
    "                test_blasts = ff[ff[gating] == 1]\n",
    "                other_cells = ff[ff[gating] == 0]\n",
    "            else:\n",
    "                test_blasts = ff[ff[\"Blast\"] == 1]\n",
    "                other_cells = ff[ff[\"Blast\"] == 0]\n",
    "            other_cells[\"pred\"] = 0\n",
    "            \n",
    "            # nuSVM\n",
    "            output_file = LAIP29_output + \"/benchmark/\" + sample_id + \"_\" + gating + \"_nuSVM.csv\"\n",
    "            if not os.path.exists(output_file):\n",
    "                test_blasts[\"pred\"] = nuSVMs[gating][tube].predict(test_blasts[markers])\n",
    "                pred = np.where(test_blasts[\"pred\"] == -1, 1, 0)\n",
    "                test_blasts[\"pred\"] = pred\n",
    "                concat = pd.concat([test_blasts, other_cells])\n",
    "                if gating == \"GMMclf\":\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_pred) * 100\n",
    "                else:\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_manual) * 100\n",
    "                result = {\"sample_id\": sample_id,\n",
    "                          \"timepoint\": timepoint,\n",
    "                          \"gating\": gating,\n",
    "                          \"model\": \"nuSVM\",\n",
    "                          \"gt_count\": len(concat[concat[\"LAIP\"]==1]),\n",
    "                          \"MRD\": MRD_status,\n",
    "                          \"MRD%\": biggest_LAIP,\n",
    "                          \"LAIP%\": LAIP_perc,\n",
    "                          \"pred_count\": len(concat[concat[\"pred\"] == 1]),\n",
    "                          \"cMRD%\": cMRD_perc,\n",
    "                          \"accuracy\": accuracy_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"precision\": precision_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"recall\": recall_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"f1\": f1_score(concat[\"LAIP\"], concat[\"pred\"])}\n",
    "                result = pd.DataFrame([result])\n",
    "                result.to_csv(output_file)\n",
    "                \n",
    "            # LOF\n",
    "            output_file = LAIP29_output + \"/benchmark/\" + sample_id + \"_\" + gating + \"_LOF.csv\"\n",
    "            if not os.path.exists(output_file):\n",
    "                test_blasts[\"pred\"] = LOF[gating][tube].predict(test_blasts[markers])\n",
    "                pred = np.where(test_blasts[\"pred\"] == -1, 1, 0)\n",
    "                test_blasts[\"pred\"] = pred\n",
    "                concat = pd.concat([test_blasts, other_cells])\n",
    "                if gating == \"GMMclf\":\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_pred) * 100\n",
    "                else:\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_manual) * 100\n",
    "                result = {\"sample_id\": sample_id,\n",
    "                          \"timepoint\": timepoint,\n",
    "                          \"gating\": gating,\n",
    "                          \"model\": \"LOF\",\n",
    "                          \"gt_count\": len(concat[concat[\"LAIP\"]==1]),\n",
    "                          \"MRD\": MRD_status,\n",
    "                          \"MRD%\": biggest_LAIP,\n",
    "                          \"LAIP%\": LAIP_perc,\n",
    "                          \"pred_count\": len(concat[concat[\"pred\"] == 1]),\n",
    "                          \"cMRD%\": cMRD_perc,\n",
    "                          \"accuracy\": accuracy_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"precision\": precision_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"recall\": recall_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"f1\": f1_score(concat[\"LAIP\"], concat[\"pred\"])}\n",
    "                result = pd.DataFrame([result])\n",
    "                result.to_csv(output_file)\n",
    "                \n",
    "            # UMAP-HDBSCAN\n",
    "            output_file = LAIP29_output + \"/benchmark/\" + sample_id + \"_\" + gating + \"_UMAP-HDBSCAN.csv\"\n",
    "            if not os.path.exists(output_file):\n",
    "                # Get the reference blasts\n",
    "                ref_blasts = ref_data[gating][tube]\n",
    "                test_blasts[\"pred\"] = UMAP_HDBSCAN(test_blasts, ref_blasts)\n",
    "                concat = pd.concat([test_blasts, other_cells])\n",
    "                if gating == \"GMMclf\":\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_pred) * 100\n",
    "                else:\n",
    "                    cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_manual) * 100\n",
    "                result = {\"sample_id\": sample_id,\n",
    "                          \"timepoint\": timepoint,\n",
    "                          \"gating\": gating,\n",
    "                          \"model\": \"UMAP-HDBSCAN\",\n",
    "                          \"gt_count\": len(concat[concat[\"LAIP\"]==1]),\n",
    "                          \"MRD\": MRD_status,\n",
    "                          \"MRD%\": biggest_LAIP,\n",
    "                          \"LAIP%\": LAIP_perc,\n",
    "                          \"pred_count\": len(concat[concat[\"pred\"] == 1]),\n",
    "                          \"cMRD%\": cMRD_perc,\n",
    "                          \"accuracy\": accuracy_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"precision\": precision_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"recall\": recall_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                          \"f1\": f1_score(concat[\"LAIP\"], concat[\"pred\"])}\n",
    "                result = pd.DataFrame([result])\n",
    "                result.to_csv(output_file)\n",
    "                \n",
    "            # GMM\n",
    "            output_file = LAIP29_output + \"/benchmark/\" + sample_id + \"_\" + gating + \"_GMM.csv\"\n",
    "            if not os.path.exists(output_file):\n",
    "                ref_model = refGMMs[gating][tube]\n",
    "                results = []\n",
    "                for percentile in percentiles[gating][tube]:\n",
    "                    cutoff = percentiles[gating][tube][percentile]\n",
    "                    test_blasts[\"pred\"] = GMM_anomaly(test_blasts, ref_model, cutoff)\n",
    "                    concat = pd.concat([test_blasts, other_cells])\n",
    "                    if gating == \"GMMclf\":\n",
    "                        cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_pred) * 100\n",
    "                    else:\n",
    "                        cMRD_perc = (len(concat[concat[\"pred\"] == 1]) / WBC_count_manual) * 100\n",
    "                    result = {\"sample_id\": sample_id,\n",
    "                              \"timepoint\": timepoint,\n",
    "                              \"gating\": gating,\n",
    "                              \"model\": \"GMM\",\n",
    "                              \"percentile\": percentile,\n",
    "                              \"gt_count\": len(concat[concat[\"LAIP\"]==1]),\n",
    "                              \"MRD\": MRD_status,\n",
    "                              \"MRD%\": biggest_LAIP,\n",
    "                              \"LAIP%\": LAIP_perc,\n",
    "                              \"pred_count\": len(concat[concat[\"pred\"] == 1]),\n",
    "                              \"cMRD%\": cMRD_perc,\n",
    "                              \"accuracy\": accuracy_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                              \"precision\": precision_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                              \"recall\": recall_score(concat[\"LAIP\"], concat[\"pred\"]),\n",
    "                              \"f1\": f1_score(concat[\"LAIP\"], concat[\"pred\"])}\n",
    "                    results.append(result)\n",
    "                result = pd.DataFrame(results)\n",
    "                result.to_csv(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
